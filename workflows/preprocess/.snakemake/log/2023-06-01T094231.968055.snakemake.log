Building DAG of jobs...
Using shell: /usr/local/bin/bash
Provided cores: 1 (use --cores to define parallelism)
Rules claiming more threads will be scaled down.
Job stats:
job           count    min threads    max threads
----------  -------  -------------  -------------
save_table        1              1              1
total             1              1              1

Select jobs to execute...

[Thu Jun  1 09:42:32 2023]
rule save_table:
    input: ../../../data/prep/penguin_subset.rds
    output: ../../../results/tables/tab_1.txt
    jobid: 0
    reason: Code has changed since last execution
    resources: tmpdir=/var/folders/hl/dt523djx7_q7xjrthzjpdvc40000gn/T

[Thu Jun  1 09:42:33 2023]
Finished job 0.
1 of 1 steps (100%) done
Complete log: .snakemake/log/2023-06-01T094231.968055.snakemake.log
